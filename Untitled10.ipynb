{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZX7TFwvGk7w"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, \\\n",
    "\t\t\t\t\t\t\tconfusion_matrix, \\\n",
    "\t\t\t\t\t\t\tprecision_score, \\\n",
    "\t\t\t\t\t\t\trecall_score, \\\n",
    "                            f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GOlSaSqOLqL-"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris3.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "Sf1oWzQBOLuL",
    "outputId": "e7d3e296-fbe2-4048-807f-a729b45ffe14"
   },
   "outputs": [],
   "source": [
    "df.drop('Id',axis=1,inplace=True)\n",
    "df.columns = [\"SepalLength\",\"SepalWidthCm\",\"PetalLength\",\"PetalWidthCm\",\"Species\"]\n",
    "# df.describe()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QqDyjtEQSBN"
   },
   "outputs": [],
   "source": [
    "# Normalize = scaling.fit_transform(df[['SepalLength','SepalWidthCm','PetalLength','PetalWidthCm']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9FgWh5mNSil-",
    "outputId": "bcce0845-baeb-48e4-d149-14061f79f5e4"
   },
   "outputs": [],
   "source": [
    "# fields = ['SepalLength','SepalWidthCm','PetalLength','PetalWidthCm']\n",
    "# with open('Normalize.csv', 'w') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow(fields)\n",
    "#     writer.writerow(Normalize)\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X = df[['SepalLength','SepalWidthCm','PetalLength','PetalWidthCm']].iloc[:,:-1].values\n",
    "# y = df['Species'].iloc[:,:-1]\n",
    "X = df.iloc[:, 2:4].values\n",
    "y = df.iloc[:, 4].values\n",
    "y[:50] = 0\n",
    "y[50:100] = 1\n",
    "y[100:] = 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=100) \n",
    "\n",
    "\n",
    "print(df.iloc[:,2 :-1])\n",
    "print(df.iloc[:, 2:4])\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bpiCXfJvb97",
    "outputId": "7005dde2-e2a0-41f5-d588-046b25710ba2"
   },
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PwHJqi3Kvdnk",
    "outputId": "39212061-ab45-4c76-9c9c-2ce7b32d81b7"
   },
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "in8uY7fGvfGM",
    "outputId": "2cd10229-5a7e-428f-8dde-6e486ed522c3"
   },
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1BexE3MkPWoA"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uupdqpp9QE7z",
    "outputId": "140bbb7f-4ba4-4fb6-a9a9-de94f586bbfc"
   },
   "outputs": [],
   "source": [
    "# scaling=MinMaxScaler()\n",
    "normalized = preprocessing.Normalizer()\n",
    "normalized_X_train = normalized.fit_transform(X_train)\n",
    "# print(normalized_X_train)\n",
    "len(normalized_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Og7bhZEvSP-T",
    "outputId": "23f68ace-5752-4d25-e588-ba4acaf68134"
   },
   "outputs": [],
   "source": [
    "# Hasil =pd.DataFrame(scaling.fit_transform(X_train),\n",
    "#             columns=df.columns, index=df.index)\n",
    "# print(Hasil)\n",
    "normalized_X_test = normalized.transform(X_test)\n",
    "# print(normalized_X_test)\n",
    "len(normalized_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kA46Or_XGpN2"
   },
   "outputs": [],
   "source": [
    "# Helper function that combines the pattern layer and summation layer\n",
    "def rbf(centre, x, sigma):\n",
    "\t\n",
    "\tcentre = centre.reshape(1, -1)\n",
    "\n",
    "\ttemp = -np.sum((centre - x) ** 2, axis = 1)  #summ layer & hiddden layer \n",
    "\ttemp = temp / (2 * sigma * sigma)\n",
    "\ttemp = np.exp(temp)\n",
    "\tgaussian = np.sum(temp)\n",
    "\t\n",
    "\treturn gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4II_ujtEG9hr"
   },
   "outputs": [],
   "source": [
    "def subset_by_class(data, labels):\n",
    "\n",
    "\tx_train_subsets = []\n",
    "\t\n",
    "\tfor l in labels:\n",
    "\t\tindices = np.where(data['y_train'] == l)\n",
    "\t\tx_train_subsets.append(data['normalized_X_train'][indices, :])\n",
    "\n",
    "\treturn x_train_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZvfRLVnHAoS"
   },
   "outputs": [],
   "source": [
    "def PNN(data):\n",
    "\n",
    "\tnum_testset = data['normalized_X_test'].shape[0]\n",
    "\tlabels = np.unique(data['y_train'])\n",
    "\tnum_class = len(labels)\n",
    "\n",
    "\tsigma = 0.5\n",
    "\n",
    "\t# Splits the training set into subsets where each subset contains data points from a particular class\t\n",
    "\tx_train_subsets = subset_by_class(data, labels)\t\n",
    "\n",
    "\t# Variable for storing the summation layer values from each class\n",
    "\tsummation_layer = np.zeros(num_class)\n",
    "\t\n",
    "\t# Variable for storing the predictions for each test data point\n",
    "\tpredictions = np.zeros(num_testset)\n",
    "\n",
    "\tfor i, test_point in enumerate(data['normalized_X_test']):\n",
    "\t\t\n",
    "\t\tfor j, subset in enumerate(x_train_subsets):\n",
    "\t\t\t# Calculate summation layer\n",
    "\t\t\tsummation_layer[j] = np.sum(\n",
    "\t\t\t\trbf(test_point, subset[0], sigma)) / subset[0].shape[0] #calling summ layer\n",
    "\t\t\n",
    "\t\t# The index having the largest value in the summation_layer is stored as the prediction\n",
    "\t\tpredictions[i] = np.argmax(summation_layer) #output layer\n",
    "\t\n",
    "\treturn predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oxjjxPsvHEa8"
   },
   "outputs": [],
   "source": [
    "def print_metrics(y_test, predictions):\n",
    "\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print('Accuracy: {}'.format(accuracy_score(y_test, predictions) * 100)+'%')\n",
    "    print('Precision: {}'.format(precision_score(y_test, predictions, average = 'micro') * 100) +'%')\n",
    "    print('Recall: {}'.format(recall_score(y_test, predictions, average = 'micro') * 100)+ '%')\n",
    "    print('F1 Score: {}'.format(f1_score(y_test, predictions, average = 'micro') * 100)+ '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zi7CwYqgHHSH",
    "outputId": "039c2084-c062-4588-b118-0bad2132d665"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\tdata = {'normalized_X_train': normalized_X_train, \n",
    "\t\t\t    'normalized_X_test': normalized_X_test, \n",
    "\t\t\t    'y_train': y_train, \n",
    "\t\t\t    'y_test': y_test}\n",
    "\tpredictions = PNN(data)\n",
    "\tprint_metrics(data['y_test'], predictions)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
